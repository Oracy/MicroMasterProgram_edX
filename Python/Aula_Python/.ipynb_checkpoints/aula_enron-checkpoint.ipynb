{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AULA - PREPARAÇÃO BÁSICA DE DADOS PARA MINERAÇÃO\n",
    "\n",
    "#### Big Data & Analytics, PUCPR\n",
    "#### Prof. Jean Paul Barddal, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta aula, utilizaremos a base de dados da Enron para conhecer \n",
    "algumas bibliotecas bastante úteis de Python para tratamento e \n",
    "prepação de dados.\n",
    "\n",
    "Nos anos 2000, a Enron era uma das maiores empresas dos Estados Unidos. Em 2002, ela quebrou devido a uma fraude de grande escala. Como resultado de uma investigação federal, uma quantidade significante de dados confidenciais se tornaram públicos, incluindo dezenas de milhares de e-mails e informações financeiras para muitos executivos da empresa.\n",
    "Nosso objetivo nesta aula é a de preparar os dados para que eles \n",
    "sejam usados para treinar um modelo de classificação que seja \n",
    "capaz de prever se uma pessoa é um não um POI no contexto do escândalo da Enron.\n",
    "\n",
    "Como etapas desta aula, elenca-se:\n",
    "    \n",
    "1. Carregamento dos dados\n",
    "2. Verificação dos tipos dos dados\n",
    "3. Estatísticas básicas dos dados\n",
    "4. Contagem de POIs\n",
    "5. Contagem de valores faltantes\n",
    "6. Remoção de valores faltantes\n",
    "7. Imputação\n",
    "8. Identificação e remoção de outliers\n",
    "9. Criação de um novo atributo\n",
    "10. Escala dos dados\n",
    "11. Classificadores\n",
    "13. Avaliação\n",
    "14. Validação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregamento de pacotes\n",
    "\n",
    "Neste projeto, vamos usar os seguintes pacotes:\n",
    "* pandas (carregamento e tratamento de dados)\n",
    "* matplotlib (para gráficos)\n",
    "* scikit-learn (aprendizagem de máquina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# por enquanto, vamos carregar apenas o pandas e o numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# vamos carregar também o método display\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Notem que temos dois tipos de dados aqui: **\n",
    "* Dados financeiros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "financial_features = ['salary', 'deferral_payments', 'total_payments',\n",
    "                     'loan_advances', 'bonus',\n",
    "                     'restricted_stock_deferred', 'deferred_income',\n",
    "                     'total_stock_value', 'expenses',\n",
    "                     'exercised_stock_options', 'other',\n",
    "                     'long_term_incentive', 'restricted_stock', 'director_fees']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dados sobre emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_features = ['to_messages', 'email_address',\n",
    "                 'from_poi_to_this_person', 'from_messages', \n",
    "                  'from_this_person_to_poi', 'shared_receipt_with_poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estatísticas dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contagem de POIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contagem de valores faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** A maioria dos classificadores não trabalha bem com valores faltantes. Então devemos tratá-los de alguma forma. Vamos trabalhar da seguinte forma aqui: caso um atributo possua mais de 40% de seus valores faltantes, vamos removê-lo, caso contrário, vamos imputar seus valores com a média dos valores restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Removendo atributos com mais de 50% de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Imputando os valores restantes com a média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identificação e remoção de outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para gráficos, vamos importar o matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "### primeiramente, vamos dar uma olhada em atributos de emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 3 pontos mais \"isolados\" e que parecem ser muito diferentes dos demais.\n",
    "Dois deles possuem os maiores valores para `to_messages`, e o outro para `from_messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos ordenar os nossos dados por `from_messages` em ordem decrescente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que o Sr. Kaminski gostava bastante de enviar e-mails, mas ele não parece ser um outlier.\n",
    "\n",
    "Vamos agora analizar a variável `to_messages`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, mais um alarme falso, parece que o Sr. Shapiro recebia muitos e-mails, mas não é um outlier.\n",
    "\n",
    "Bem, nós poderíamos continuar com esse processo para analizar cada variável, mas vamos analizar pelo menos mais duas.\n",
    "Agora, vamos escolher duas variáveis financeiras: `expenses` e `salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem, isso parece um pouco bizarro, não? Nós temos um ponto **MUITO** diferente dos demais.\n",
    "Vamos repetir o processo que usamos anteriormente para verificar qual dado é este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahá, essa linha é apenas um agregado das demais. \n",
    "Na prática, este dado deve ser removido, pois ele não representa um indivíduo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o gráfico sem esse outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DESAFIOS\n",
    "Existem vários outliers neste conjunto de dados, mas dois são bem fáceis de encontrar:\n",
    "1. Um possui todos os seus valores faltantes.\n",
    "2. E o outro também não é um indivíduo.\n",
    "\n",
    "Como atividade extra, considere continuar trabalhando na base de dados para encontrar estes dados e removê-los.\n",
    "\n",
    "Além destes dois outliers, nós podemos continuar nossa análise usando outros métodos estatísticos um pouco mais interessantes.\n",
    "Um exemplo seria usar o método IQR ([Inter-Quartile Range](https://stackoverflow.com/questions/34782063/how-to-use-pandas-filter-with-iqr)). Normalmente, este método nos ajuda a encontrar outliers de forma bastante rápida.\n",
    "Como você verá no link acima, é bastante fácil executá-lo usando o pandas!\n",
    "\n",
    "**Nota: não esqueça que não podemos remover POIs desta base de dados, caso contrário, a tarefa de aprendizagem se tornará ainda mais difícil pois estaremos desbalanceando ainda mais o problema!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleção básica de atributos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos acima, existem três atributos do tipo `object`. Se abrirmos nossos dados no excel, veremos que dois destes dados são apenas `strings` e o outro é nossa classe, `poi`.\n",
    "Aqui, temos que tomar cuidado e pensar nas seguintes possibilidades:\n",
    "1. Os dados são `string`, mas trata-se de um atributo categórico.\n",
    "2. Os dados são `string` e são inúteis.\n",
    "3. Os dados são `string` e necessitam de tratamento especial.\n",
    "4. O dado pode ser convertido para valores numéricos discretos.\n",
    "\n",
    "* No caso #1, vamos precisar usar um processamento como [OneHotEncoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) antes de efetivamente realizar a aprendizagem. Note que no WEKA, isso não é necessário, mas caso usem o `scikit-learn`, isso é necessário.\n",
    "* No caso #2, que é o que ocorre neste projeto, podemos apenas remover os atributos.\n",
    "* No caso #3, precisamos tratar os dados usando [Bag of Words](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) e/ou [TF-IDF](https://stackoverflow.com/questions/37593293/what-is-the-simplest-way-to-get-tfidf-with-pandas-dataframe).\n",
    "* No caso #4, podemos simplesmente substituir os valores de outros tipos para que eles se tornem numéricos, como por exemplo, `True por 1` e `False por 0`.\n",
    "\n",
    "Felizmente, os atributos `email_address` e `name` são strings que funcionam como identificadores, e este tipo de dado não ajuda na **generalização**, então vamos removê-los:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remoção de email e name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos agora substituir os True e False para que se tornem valores numéricos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação de um novo atributo\n",
    "\n",
    "Muitas vezes, os atributos originais podem não ser suficientes, mas algumas pequenas transformações podem ser úteis e facilitar a vida de nossos classificadores. Uma técnica bastante comum é a criação de novos atributos. Para criar um novo atributo, precisamos apenas ter uma hipótese do por quê este novo atributo seja útil na nossa tarefa de classificação.\n",
    "\n",
    "A seguir, vamos criar um novo atributo chamado `wealth`. Este atributo será simplesmente a soma de todos os atributos financeiros de uma pessoa. A hipótese neste caso é de que algumas pessoas podem ter salários baixos mas valores de bonificação altos, o que poderia ser um indicativo de fraude. Ao somar estas variáveis, nós (e o classificador) teremos uma melhor noção de quanto dinheiro cada pessoa realmente está ganhando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos começar ao arrumar o vetor que inicializamos lá no topo do código, `financial_features`\n",
    "\n",
    "# como removemos algumas variáveis, vamos pegar a interseção entre essas variáveis e as variáveis\n",
    "# que temos agora no dataset\n",
    "\n",
    "\n",
    "# `wealth` é a soma dos atributos financeiros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escala dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar mais uma olhada nos valores mínimos e máximos de cada atributos que temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que existem atributos que estão na escala de `10E8`, enquanto existem alguns que estão na casa de dezenas de milhares.\n",
    "Existem classificadores que podem ser afetados por isso, como o kNN!\n",
    "\n",
    "O motivo disso é que o kNN se baseia em cálculos de distância, e a distância é proporcional aos valores máximos e mínimos que um atributo pode assumir.\n",
    "Não vamos detalhar isso, mas imaginem o seguinte:\n",
    "\n",
    "Queremos calcular a distância entre **dois pontos A e B**.\n",
    "\n",
    "**Atributo A**: \n",
    "* Ponto 1: possui valor `10`\n",
    "* Ponto 2: possui valor `1000`\n",
    "* A distância (diferença), seria `1000-10 = 900`\n",
    "\n",
    "**Atributo B**:\n",
    "* Ponto 1: possui valor `1`\n",
    "* Ponto 2: possui valor `10`\n",
    "* A distância (diferença), seria `10-1 = 9`\n",
    "\n",
    "Neste caso, o atributo A seria mais *impactante* no nosso cálculo de distância, e isso não é preferível se não conhecemos bem os dados. O ideal é que todos os dados possuam o mesmo *impacto*!\n",
    "\n",
    "Uma boa prática, independentemente de ser necessário ou não, é sempre alterar a escala dos dados.\n",
    "Vamos fazer isso usando o método [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificadores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar qual classificador deve ser usado não é uma tarefa simples.\n",
    "Por mais que existam \"dogmas\" na área comentando que algoritmos baseados em \n",
    "instâncias são superiores quando possuímos apenas dados numéricos, não há \n",
    "prova formal que confirme tais afirmações.\n",
    "\n",
    "Como devemos proceder? O ideal é testar diversos classificadores, sendo cada um de um tipo diferente (**bias**).\n",
    "Por exemplo, podemos testar um classificador probabilístico ([Gaussian Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)), um baseado em árvore de decisão ([Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) e um baseado em instâncias ([kNN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# vamos criar uma lista com um classificador de cada tipo para testarmos na sequência\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, maior parte das pessoas trabalham com **acurácia** para determinar quão bom um classificador é.\n",
    "Isso não está errado, mas ao usar essa métrica, temos que tomar cuidado.\n",
    "Digamos que nós temos um classificador bem ingênuo que não aprendeu nada, e para cada questionamento que fazemos para ele, ele nos afirma que um indivíduo **não é um POI**.\n",
    "Lembre-se, na nossa base de dados, nós temos 18 indivíduos que são POIs e 128 que não são POIs.\n",
    "Neste caso, a acurácia desse modelo seria de 128/146, significando que ele acertaria quase 90% dos dados.\n",
    "Contudo, esse classificador jamais identificaria para nós sequer um POI!\n",
    "\n",
    "* Como resolvemos isso de forma mais adequada?\n",
    "\n",
    "Existem duas métricas que são utilizadas em problemas desbalanceados: **precision** e **recall**.\n",
    "\n",
    "* **Precision:** Precision é a proporção de POIs que foram identificados corretamente, em relação a todos os POIs que nosso classificador identificou.\n",
    "* **Recall:** Recall é a proporção dos POIs que foram identificados em relação a todos os POIs da base.\n",
    "\n",
    "Para saber mais, dê uma olhada [aqui](https://en.wikipedia.org/wiki/Precision_and_recall) e [aqui](https://hackercollider.com/articles/2016/06/03/recall-vs-precision/)!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A idéia geral de criar modelos preditivos é que estes sejam capazes de **generalizar** bem.\n",
    "Deste modo, após criar um modelo, nós devemos testá-lo usando dados **diferentes** dos usados durante o treinamento.\n",
    "Existem diversas formas de fazer isso, mas como o nosso dataset é pequeno, a opção mais interessante é usar [validação cruzada](https://pt.wikipedia.org/wiki/Validação_cruzada).\n",
    "Contudo, existe uma variação de validação cruzada que é ainda mais interessante e que faz muito sentido neste projeto: uma validação cruzada [estratificada](https://stats.stackexchange.com/questions/49540/understanding-stratified-cross-validation). Este procedimento tem como objetivo fazer com que cada *fold* possua a mesma distribuição de classes que o dataset original.\n",
    "\n",
    "Vamos agora usar esse procedimento para testar os três classificadores e verificar os resultados em termos de **precision** e **recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Código para teste de um classificador usando validação cruzada estratificada\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def evaluateClassifier(clf, dataset, folds = 5):\n",
    "    X = dataset.drop('poi', axis = 1).values\n",
    "    X = StandardScaler().fit_transform(X) # escala de dados\n",
    "    y = dataset['poi'].values\n",
    "    cv = StratifiedShuffleSplit(y, random_state=42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_indices, test_indices in cv:\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "        ### treinamento do classificador\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        ### obtenção de predições para os dados de teste\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        ### cálculo da matriz de confusão\n",
    "        for prediction, truth in zip(predictions, y_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print(\"Erro! Encontramos um valor diferente de 0 ou 1!\")\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "    except:\n",
    "        print(\"Houve uma divisão por zero!\")\n",
    "    print(\"{} \\n \\t Accuracy = {} \\n \\t Precision = {} \\n \\t Recall = {}\\n\\n\".format(clf, accuracy, precision, recall))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### PRÓXIMOS PASSOS - TUNING\n",
    "\n",
    "Muitos classificadores dependes de seus parâmetros. Um exemplo é o SVM, onde os parâmetros padrão normalmente não dão resultados bons. \n",
    "Os resultados que obtivemos acima são razoáveis, pois existem muitos processos a mais de limpeza e criação de novos atributos que poderíamos ter feito.\n",
    "Outra forma de tentar melhorar os nossos resultados é através de **tuning**, onde podemos avaliar diferentes parametrizações para um classificador e manter apenas a que nos dá melhores resultados.\n",
    "Como trabalho extra, experimente usar o método [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para tunar os 3 classificadores que usamos acima, e compare os resultados obtidos com os originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRÓXIMOS PASSOS - SELEÇÃO AUTOMÁTICA DE ATRIBUTOS\n",
    "\n",
    "Neste projeto, nós estamos lidando com uma base de dados razoavelmente pequena, seja em número de instâncias, seja em número de atributos. Contudo, nós temos atributos nesta base de dados que são inúteis, e outros acabam até mesmo atrapalhando. Deste modo, selecionar atributos é uma tarefa extremamente importante e que nos ajudaria e muito a obter melhores resultados.\n",
    "Infelizmente, o scikit-learn original não inclui muitos métodos de seleção de atributos, mas cito aqui o [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) como um bastante útil e rápido. \n",
    "Sugiro neste ponto testar diferentes números de atributos a serem obtidos pelo `SelectKBest` e testados na criação de um classificador.\n",
    "Por exemplo:\n",
    "* kNN com 3 atributos obtidos pelo `SelectKBest`\n",
    "* kNN com 4 atributos obtidos pelo `SelectKBest`\n",
    "* kNN com 5 atributos obtidos pelo `SelectKBest`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRÓXIMOS PASSOS - COMBINANDO SELEÇÃO DE ATRIBUTOS E TUNING\n",
    "\n",
    "Um fator bastante importante em aprendizagem de máquina é o viés indutivo (inductive bias) dos classificadores.\n",
    "Ou seja, cada classificador \"percebe\" os dados de uma forma diferente, e assim, usa os mesmos atributos de formas diferentes para de fato extrair padrões e aprender um modelo preditivo.\n",
    "Desta forma, seria interessante que cada classificador fosse tunado com diferentes conjuntos de atributos, unindo então o `GridSearch` e um método de seleção de atributos, como o `SelectKBest`.\n",
    "Felizmente, isso é bastante fácil de se fazer ao usar a classe [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
